{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty gpu cache\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir = os.getcwd()\n",
    "model_dir = os.path.join(notebook_dir, \"..\", \"..\", \"..\", \"..\", \"local-models/Llama-3.2-1B\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    #torch_dtype=torch.float16,  # Use half precision to reduce memory usage\n",
    "    low_cpu_mem_usage=True,     # Load the model with memory optimization\n",
    "    device_map=device          # Automatically handle device placement\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = [\n",
    "    \"A lonely robot found a broken music box in an abandoned city. As he fixed it, the melody attracted other robots. Together, they created the city's first robot orchestra.\",\n",
    "    \"The last seed on Earth was planted by a child in her grandmother's garden. Against all odds, it grew into a magical tree that produced seeds of every plant that had been lost.\",\n",
    "    \"In a world where dreams were visible as floating bubbles, a young girl discovered she could weave them into blankets. Her creations brought comfort to those suffering from nightmares.\",\n",
    "    \"An old lighthouse keeper discovered that his beacon didn't guide ships, but rather lost stars back to their constellations. Each night, he helped rebuild the night sky.\",\n",
    "    \"Deep in the digital forest, a virus learned to heal corrupted files instead of destroying them. Other programs began calling it the Digital Doctor.\",\n",
    "    \"A time-traveling mailman accidentally delivered letters to the wrong centuries. The resulting mix-ups created unexpected friendships across time.\",\n",
    "    \"The last bookstore on Mars housed a librarian who could bring characters to life by reading aloud. She used this gift to help homesick colonists feel less alone.\"\n",
    "]\n",
    "\n",
    "summaries = [\n",
    "    \"A robot repairs a music box and builds community through music.\",\n",
    "    \"A child's last seed miraculously restores Earth's lost plants.\",\n",
    "    \"A girl turns visible dreams into comforting blankets for nightmare sufferers.\",\n",
    "    \"A lighthouse keeper helps lost stars find their way back to constellations.\",\n",
    "    \"A benevolent virus becomes known for healing corrupted files.\",\n",
    "    \"A mailman's time-travel mistakes lead to cross-century friendships.\",\n",
    "    \"A Martian librarian uses her power to comfort colonists with living stories.\"\n",
    "]\n",
    "\n",
    "alternative_stories = [\n",
    "    \"In a forgotten city, a solitary robot stumbled upon an ancient piano. As it played, the harmonious notes summoned other robots, and together they formed a symphony that echoed through the empty streets.\",\n",
    "    \"A young girl planted a mysterious seed in a barren land. To everyone's amazement, it sprouted into a tree that bore fruits of every extinct plant, reviving the world's lost flora.\",\n",
    "    \"In a realm where dreams floated like clouds, a girl learned to capture them in jars. Her bottled dreams provided solace to those haunted by restless nights.\",\n",
    "    \"An old lighthouse keeper discovered that his beacon didn't guide ships, but rather lost stars back to their constellations. Each night, he helped rebuild the night sky.\",\n",
    "\n",
    "]\n",
    "\n",
    "alternative_summaries = [\n",
    "    \"A robot finds a piano and unites others through music.\",\n",
    "    \"A girl's seed grows into a tree that revives extinct plants.\",\n",
    "    \"A girl captures dreams to comfort those with nightmares.\",\n",
    "    \"A lighthouse keeper helps lost stars find their way back to constellations.\",\n",
    "\n",
    "]\n",
    "pairs_train = pd.DataFrame({\"text\": stories, \"target\": summaries})\n",
    "pairs_val = pd.DataFrame({\"text\": alternative_stories, \"target\": alternative_summaries})\n",
    "pairs_train = Dataset.from_pandas(pairs_train)\n",
    "pairs_val = Dataset.from_pandas(pairs_val)\n",
    "pairs = DatasetDict({\"train\": pairs_train, \"validation\": pairs_val})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenize_function(example, tokenizer):\n",
    "    inputs = tokenizer(example[\"text\"], add_special_tokens=True) # only gonna add bos\n",
    "    targets = tokenizer(example[\"target\"], add_special_tokens=False) # we will manually add eos\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_input_ids =  inputs[\"input_ids\"][i] \n",
    "        sample_label_input_ids = targets[\"input_ids\"][i] + [tokenizer.eos_token_id]\n",
    "        inputs[\"input_ids\"][i] = sample_input_ids + sample_label_input_ids\n",
    "        targets[\"input_ids\"][i] = [-100] * len(sample_input_ids) + sample_label_input_ids\n",
    "        inputs[\"attention_mask\"][i] = [1] * len(inputs[\"input_ids\"][i])\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    # input_ids, attention_mask, and labels are all the same length for a given sample, but not across samples\n",
    "    # so we need to pad to max length from left side\n",
    "\n",
    "    max_length = max([len(x) for x in inputs[\"input_ids\"]])\n",
    "    # add padding tokens to the left side of the input ids, attention mask, and labels\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        inputs[\"input_ids\"][i] = ([tokenizer.pad_token_id] * \n",
    "                                (max_length - len(inputs[\"input_ids\"][i])) + \n",
    "                                inputs[\"input_ids\"][i])\n",
    "        inputs[\"attention_mask\"][i] = ([0] * (max_length - len(inputs[\"attention_mask\"][i])) +\n",
    "                                    inputs[\"attention_mask\"][i])\n",
    "        inputs[\"labels\"][i] = ([-100] * (max_length - len(inputs[\"labels\"][i])) +\n",
    "                                inputs[\"labels\"][i])\n",
    "        \n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_dataset = pairs.map(\n",
    "        lambda x: tokenize_function(x, tokenizer=tokenizer),\n",
    "        batched=True,\n",
    "        remove_columns=pairs['train'].column_names,\n",
    "        load_from_cache_file=False,\n",
    "        desc=\"Running tokenizer on train dataset\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in pairs_dataset:\n",
    "    print(split)\n",
    "    for i in range(len(pairs_dataset[split][\"input_ids\"])):\n",
    "        print(pairs_dataset[split][\"input_ids\"][i])   \n",
    "        print(len(pairs_dataset[split]  [\"input_ids\"][i]))\n",
    "        print(pairs_dataset[split][\"attention_mask\"][i])  \n",
    "        print(len(pairs_dataset[split][\"attention_mask\"][i]))\n",
    "        print(pairs_dataset[split][\"labels\"][i])\n",
    "        print(len(pairs_dataset[split][\"labels\"][i]))\n",
    "        print(\"-\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    pairs_dataset['train'], shuffle=True, collate_fn=default_data_collator, batch_size=2\n",
    ")\n",
    "dev_dataloader = DataLoader(\n",
    "    pairs_dataset['validation'], shuffle=True, collate_fn=default_data_collator, batch_size=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dev_dataloader:\n",
    "    print(\"-\"*100)\n",
    "    print(\"train batch\")\n",
    "    for i in range(len(batch[\"input_ids\"])):\n",
    "        print(f\"number {i}\")\n",
    "        print(batch[\"input_ids\"][i])   \n",
    "        print(len(batch[\"input_ids\"][i]))\n",
    "        print(batch[\"attention_mask\"][i])  \n",
    "        print(len(batch[\"attention_mask\"][i]))\n",
    "        print(batch[\"labels\"][i])\n",
    "        print(len(batch[\"labels\"][i]))\n",
    "        print(\"-\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
