finetune_config:
    llm_name: "Llama-3.2-1B"
    method: "finetune"
    batch_size: 1
    max_epochs: 8
    lr0: 1.0e-5
    patience_ratio: 0.10
    gradient_accumulation_steps: 16
    lr_schedule: "linear_decay"
    lr_warmup_steps_ratio: 0.15
