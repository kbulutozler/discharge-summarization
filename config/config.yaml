finetune_config:
  llm_name: "Llama-3.2-1B-Instruct"
  method: "finetune"
  batch_size: 1
  max_epochs: 2
  lr0: 1.0e-3
  patience_ratio: 0.10
  gradient_accumulation_steps: 2
  lr_schedule: "linear_decay"
  lr_warmup_steps_ratio: 0.15
